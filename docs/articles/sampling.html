<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Simulationsbasierte Posteriori-Inferenz • bayeskurs</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><meta property="og:title" content="Simulationsbasierte Posteriori-Inferenz">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">bayeskurs</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">0.3.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/index.html">Themen</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="http://www.bioimg.statistik.uni-muenchen.de">Bioimaging Group</a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Simulationsbasierte Posteriori-Inferenz</h1>
                        <h4 class="author">Volker Schmid</h4>
            
            <h4 class="date">Mai 2017</h4>
      
      
      <div class="hidden name"><code>sampling.Rmd</code></div>

    </div>

    
    
<div id="einfuhrung" class="section level1">
<h1 class="hasAnchor">
<a href="#einfuhrung" class="anchor"></a>Einführung</h1>
<div id="zielsetzung" class="section level2">
<h2 class="hasAnchor">
<a href="#zielsetzung" class="anchor"></a>Zielsetzung</h2>
<p>Für komplexere Modelle ist die Posteriori of nicht mehr analytisch zugänglich. Insbesondere ist die Normalisierungskonstante, d.h., die marginale Likelihood <span class="math display">\[ p(x)=\int f(x|\theta)p(\theta)d\theta \]</span> schwer zu berechnen. Auswege:</p>
<ul>
<li>Numerische Integration</li>
<li>Approximation der Posteriori</li>
<li>Simulationsverfahren</li>
</ul>
</div>
<div id="simulationsbasierte-posteriori-inferenz-idee" class="section level2">
<h2 class="hasAnchor">
<a href="#simulationsbasierte-posteriori-inferenz-idee" class="anchor"></a>Simulationsbasierte Posteriori-Inferenz Idee:</h2>
<p>Erzeuge Ziehungen aus der Posteriori-Verteilung und approximiere daraus Statistiken der Posteriori-Verteilung</p>
<ul>
<li>Posteriori-Erwartungswert durch den Mittelwert</li>
<li>Posteriori-Median über Median der Stichprobe</li>
<li>Quantile der Posteriori-Verteilung über Quantile der Stichprobe</li>
<li>HPD-Intervalle als kürzeste Intervalle, die <span class="math inline">\(100(1-\alpha)\%\)</span> der Stichprobe enthalten</li>
</ul>
</div>
</div>
<div id="monte-carlo-integration" class="section level1">
<h1 class="hasAnchor">
<a href="#monte-carlo-integration" class="anchor"></a>Monte-Carlo-Integration</h1>
<div id="definition" class="section level2">
<h2 class="hasAnchor">
<a href="#definition" class="anchor"></a>Definition</h2>
<p>Sei <span class="math inline">\(f(x)&gt;0\)</span> eine beliebige stetige Funktion mit bekanntem Wertebereich <span class="math inline">\([0,Y]\)</span>. <span class="math inline">\(\int_a^b f(x) dx\)</span> kann wie dann folgt approximiert werden.</p>
<ul>
<li>Ziehe <span class="math inline">\(n\)</span> gleichverteilte Zufallszahlen <span class="math inline">\(x\)</span> aus <span class="math inline">\([a,b]\)</span>
</li>
<li>Ziehe unabhängig davon <span class="math inline">\(n\)</span> gleichverteilte Zufallszahlen <span class="math inline">\(y\)</span> aus <span class="math inline">\([0,Y]\)</span>
</li>
<li>Berechne den Anteil <span class="math inline">\(h\)</span> der Punkte <span class="math inline">\((x_i,y_i)\)</span>, die unterhalb der Funktion <span class="math inline">\(f\)</span> liegen</li>
<li><span class="math inline">\(\int_a^b f(x) dx \approx h(b-a)Y\)</span></li>
</ul>
</div>
<div id="beispiel" class="section level2">
<h2 class="hasAnchor">
<a href="#beispiel" class="anchor"></a>Beispiel</h2>

</div>
<div id="monte-carlo-schatzer" class="section level2 allowframebreaks">
<h2 class="hasAnchor">
<a href="#monte-carlo-schatzer" class="anchor"></a>Monte-Carlo-Schätzer</h2>
<p>Ist <span class="math inline">\(p(x)\)</span> eine Dichte, so können Integrale der Form<span class="math display">\[ E(g(x))=\int g(x)p(x) dx \]</span> mit einer Stichprobe <span class="math inline">\(x_1,\ldots,x_m\)</span> aus <span class="math inline">\(p(x)\)</span> durch den Stichprobenmittelwert</p>
<p><span class="math display">\[ 
\bar{g}_m=\frac{1}{m}\sum_{i=1}^mg\left(x_i\right) \]</span></p>
<p>approximiert werden. Aus dem starken Gesetz der grossen Zahlen folgt</p>
<p><span class="math display">\[ \lim \frac{1}{m} \sum_{i=1}^m
g(x_i)\to \int g(x)p(x)dx. \]</span></p>
<p>Die Varianz des Monte-Carlo-Schätzers <span class="math inline">\(\bar{g}_m\)</span> ist gegeben durch</p>
<p><span class="math display">\[ 
Var(\bar{g}_m)=\frac{1}{m}\int\left(g(X)-E(g(x))\right)^2
p(x)dx=\frac{1}{m}Var(g). \]</span></p>
<p>Der Approximationsfehler verringert sich mit steigendem <span class="math inline">\(m\)</span>. Es folgt sogar aus dem zentralen Grenzwertsatz</p>
<p><span class="math display">\[ 
\sqrt{m}\left(g_m-E(g(x))\right)\sim N(0,Var(g)). \]</span></p>
<p>Schätzer für <span class="math inline">\(Var(\bar{g}_m)\)</span> ist</p>
<p><span class="math display">\[ \widehat{Var(\bar{g}_m)}=\frac{1}{m-1}\sum_{i=1}^m 
\left(g(x_i)-\bar{g}_m\right)^2 \]</span></p>
</div>
</div>
<div id="ziehen-von-zufallsvariablen" class="section level1">
<h1 class="hasAnchor">
<a href="#ziehen-von-zufallsvariablen" class="anchor"></a>Ziehen von Zufallsvariablen</h1>
<div id="inversionsmethode" class="section level2">
<h2 class="hasAnchor">
<a href="#inversionsmethode" class="anchor"></a>Inversionsmethode</h2>
<p>Gegeben sei die Verteilungsfunktion <span class="math inline">\(F(x)\)</span> einer Zufallsvariablen <span class="math inline">\(X\)</span>. Sei <span class="math inline">\(u\sim U[0,1]\)</span>. Dann ist <span class="math display">\[ Y = F^{-1}(u) = \inf\{y:F(y)\geq u\} \sim X \]</span></p>
</div>
<div id="acception-rejection-methode" class="section level2">
<h2 class="hasAnchor">
<a href="#acception-rejection-methode" class="anchor"></a>Acception-Rejection-Methode</h2>
<p>Ziel: Wir wollen aus einer Dichtefunktion <span class="math inline">\(f(x)\)</span> ziehen. Gegeben sei eine Dichtefunktion <span class="math inline">\(g(x)\)</span>, nach der wir problemlos Zufallszahlen ziehen können. Es existiere ein <span class="math inline">\(c\)</span>, so dass <span class="math display">\[ cg(z)\geq f(z) \]</span> für alle <span class="math inline">\(z\)</span> mit <span class="math inline">\(f(z)&gt;0\)</span>. Dann können Zufallszahlen gemäß <span class="math inline">\(f(x)\)</span> wie folgt gezogen werden:</p>

<ul>
<li>Wähle <span class="math inline">\(c\)</span> möglichst klein</li>
<li>Kann auch angewandt werden, falls die Normalisierungskonstante von <span class="math inline">\(f(x)\)</span> nicht bekannt</li>
</ul>
</div>
<div id="squezed-acception-rejection-sampling" class="section level2">
<h2 class="hasAnchor">
<a href="#squezed-acception-rejection-sampling" class="anchor"></a>Squezed Acception-Rejection-Sampling</h2>
<p>Gegeben sei eine untere Schranke <span class="math inline">\(s(z)\leq f(z)\)</span>. Für <span class="math inline">\(u\)</span> Ziehung aus <span class="math inline">\(U[0,1]\)</span> akzeptiere <span class="math inline">\(Z\)</span></p>

<p>Der zweite Schritt kann ausgelassen werden, wenn bereits im ersten Schritt akzeptiert wurde.</p>
</div>
</div>
<div id="markov-chain-monte-carlo-markov-chain-monte-carlo" class="section level1">
<h1 class="hasAnchor">
<a href="#markov-chain-monte-carlo-markov-chain-monte-carlo" class="anchor"></a>Markov Chain Monte Carlo ## Markov Chain Monte Carlo</h1>
<ul>
<li>Ziel: Ziehungen aus der Posterioriverteilung</li>
<li>Simulationsbasierte Inferenz</li>
<li>Funktioniert für komplexe und hochdimensionale Probleme</li>
<li>Idee: Erzeuge eine Markovkette, deren stationäre Verteilung die Posterioriverteilung ist</li>
<li>Ziehungen sind voneinander abhängig</li>
</ul>
<div id="markov-chain-monte-carlo-methoden" class="section level2">
<h2 class="hasAnchor">
<a href="#markov-chain-monte-carlo-methoden" class="anchor"></a>Markov Chain Monte-Carlo-Methoden</h2>
<p>Mit der Übergangsmatrix <span class="math inline">\(\mathbf{P}\)</span> einer irreduziblen, aperiodischen Markovkette, deren stationäre Verteilung <span class="math inline">\(\mathbf{\pi}\)</span> ist, können Zufallszahlen <span class="math inline">\(Y \sim \pi\)</span> wie folgt erzeugt werden:</p>

<p>Ab einem gewissen Index <span class="math inline">\(b\)</span>, dem  geht der Einfluss der Startverteilung verloren und es gilt approximativ</p>
<p><span class="math display">\[ y^{(t)}\sim \pi, \text{ für } i=b,\ldots,m. \]</span></p>
<p>Die Ziehungen sind identisch verteilt, aber nicht unabhängig.</p>
</div>
<div id="gibbs-sampling" class="section level2">
<h2 class="hasAnchor">
<a href="#gibbs-sampling" class="anchor"></a>Gibbs-Sampling</h2>
<p>Beim Gibbs-Sampling zieht man abwechselnd aus den Full Conditional Posteriors (vollständig bedingte Posterioriverteilung) der einzelnen Parameter(blöcke).</p>
</div>
<div id="beispiel-gibbs-sampling" class="section level2 allowframebreaks">
<h2 class="hasAnchor">
<a href="#beispiel-gibbs-sampling" class="anchor"></a>Beispiel Gibbs-Sampling</h2>
<p>Modell: <span class="math display">\[x_i \sim N(\mu, \sigma^2)\]</span></p>
<p>Likelihood: <span class="math display">\[p(\mathbf{x}|\mu,\sigma^2) =
\left( \frac{1}{2\pi\sigma^2}\right)^{n/2} \exp\left(-\frac{1}{\sigma^2}\sum
(x_i-\mu)^2\right)\]</span></p>
<p>Semi-konjugierte Prioris:</p>
<span class="math display">\[\begin{eqnarray*} 
\mu &amp;\sim&amp; N(m_0,s_0)\\ 
\tau=\sigma^{-2} &amp;\sim&amp; Ga(a,b)\\ 
\mu &amp;\perp &amp;\tau 
\end{eqnarray*}\]</span>
<p>Posteriori-Verteilung:</p>
<span class="math display">\[\begin{eqnarray*} 
p(\mu,\tau|\mathbf{x}) &amp;\propto&amp; \tau^{n/2} \exp\left(-\frac{\tau}{2}\sum (x_i-\mu)^2\right) \\ &amp;\cdot&amp; \exp\left(-\frac{1}{2s_0}(\mu-m_0)^2\right) \tau^a \exp(-b\tau) 
\end{eqnarray*}\]</span>
<p>Full conditional von <span class="math inline">\(\mu\)</span>: <span class="math display">\[ p(\mu,|\mathbf{x},\tau) \propto 
\exp\left(-\frac{\tau}{2}\sum (x_i-\mu)^2-\frac{1}{2s_0}(\mu-m_0)^2\right) \]</span></p>
<p>Es handelt sich um den Kern der N<span class="math inline">\((s^{-1}m,s^{-1})\)</span>-Verteilung mit <span class="math inline">\(m=\tau\sum x_i+m_0/s_0\)</span> und <span class="math inline">\(s=n\tau+s_0^{-1}\)</span>.</p>
<p>Full conditional von <span class="math inline">\(\tau\)</span>:</p>
<p><span class="math display">\[ p(\tau|\mathbf{x},\mu) \propto \tau^{a+n/2} 
exp\left(-(b+0.5\sum(x_i-\mu)^2)\right) \]</span></p>
<p>Es handelt sich um den Kern der Ga<span class="math inline">\((a+n/2,b+0.5\sum(x_i-\mu)^2)\)</span>-Verteilung.</p>
<p>Gibbs-Sampler:</p>
<ol style="list-style-type: decimal">
<li>Wähle Startwert <span class="math inline">\(\tau_0\)</span>
</li>
<li>Ziehe <span class="math inline">\(\mu \sim N(s^{-1}m,s^{-1})\)</span>
</li>
<li>Ziehe <span class="math inline">\(\tau \sim Ga(a+n/2,b+0.5\sum(x_i-\mu)^2)\)</span>
</li>
<li>Iteriere 2 und 3 für <span class="math inline">\(m=1,\ldots,M\)</span>
</li>
</ol>
</div>
<div id="metropolis-hastings-algorithmus" class="section level2">
<h2 class="hasAnchor">
<a href="#metropolis-hastings-algorithmus" class="anchor"></a>Metropolis-Hastings-Algorithmus</h2>

</div>
<div id="vorschlagsdichten-proposal-dichten" class="section level2">
<h2 class="hasAnchor">
<a href="#vorschlagsdichten-proposal-dichten" class="anchor"></a>Vorschlagsdichten (Proposal-Dichten)</h2>

</div>
<div id="random-walk-proposal" class="section level2">
<h2 class="hasAnchor">
<a href="#random-walk-proposal" class="anchor"></a>Random Walk-Proposal</h2>
<p>Random Walk wird in der Regel mit Normalverteilung konstruiert: <span class="math display">\[ \theta^* \sim N(\theta^{(k-1)},C) \]</span> mit vorgegebener Kovarianzmatrix <span class="math inline">\(C\)</span>.</p>

</div>
<div id="mh-algorithmus-fur-multivariate-verteilungen" class="section level2">
<h2 class="hasAnchor">
<a href="#mh-algorithmus-fur-multivariate-verteilungen" class="anchor"></a>MH-Algorithmus für Multivariate Verteilungen</h2>

</div>
<div id="metropolis-within-gibbs-sampling" class="section level2">
<h2 class="hasAnchor">
<a href="#metropolis-within-gibbs-sampling" class="anchor"></a>Metropolis-Within-Gibbs-Sampling</h2>
<ul>
<li>In der Regel zieht man bei MCMC abwechselnd aus den Parameter(blöcken)</li>
<li>Kennt man die Full Conditional-Verteilung, zieht man den Parameter(block) mittels eines Gibbs-Schritts</li>
<li>Kennt man die Full Conditional nur bis auf Konstanten, zieht man den Parameter(block) mittels eines Metopolis-Hastings-Schritts</li>
<li>Zusammen <em>Metropolis-Within-Gibbs-Sampling</em> genannt</li>
<li>Auch hier ist die Reihenfolge der Ziehungen theoretisch irrelevant, praktisch aber insbesondere für die ersten Ziehungen wichtig</li>
</ul>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#einfuhrung">Einführung</a><ul class="nav nav-pills nav-stacked">
<li><a href="#zielsetzung">Zielsetzung</a></li>
      <li><a href="#simulationsbasierte-posteriori-inferenz-idee">Simulationsbasierte Posteriori-Inferenz Idee:</a></li>
      </ul>
</li>
      <li>
<a href="#monte-carlo-integration">Monte-Carlo-Integration</a><ul class="nav nav-pills nav-stacked">
<li><a href="#definition">Definition</a></li>
      <li><a href="#beispiel">Beispiel</a></li>
      <li><a href="#monte-carlo-schatzer">Monte-Carlo-Schätzer</a></li>
      </ul>
</li>
      <li>
<a href="#ziehen-von-zufallsvariablen">Ziehen von Zufallsvariablen</a><ul class="nav nav-pills nav-stacked">
<li><a href="#inversionsmethode">Inversionsmethode</a></li>
      <li><a href="#acception-rejection-methode">Acception-Rejection-Methode</a></li>
      <li><a href="#squezed-acception-rejection-sampling">Squezed Acception-Rejection-Sampling</a></li>
      </ul>
</li>
      <li>
<a href="#markov-chain-monte-carlo-markov-chain-monte-carlo">Markov Chain Monte Carlo ## Markov Chain Monte Carlo</a><ul class="nav nav-pills nav-stacked">
<li><a href="#markov-chain-monte-carlo-methoden">Markov Chain Monte-Carlo-Methoden</a></li>
      <li><a href="#gibbs-sampling">Gibbs-Sampling</a></li>
      <li><a href="#beispiel-gibbs-sampling">Beispiel Gibbs-Sampling</a></li>
      <li><a href="#metropolis-hastings-algorithmus">Metropolis-Hastings-Algorithmus</a></li>
      <li><a href="#vorschlagsdichten-proposal-dichten">Vorschlagsdichten (Proposal-Dichten)</a></li>
      <li><a href="#random-walk-proposal">Random Walk-Proposal</a></li>
      <li><a href="#mh-algorithmus-fur-multivariate-verteilungen">MH-Algorithmus für Multivariate Verteilungen</a></li>
      <li><a href="#metropolis-within-gibbs-sampling">Metropolis-Within-Gibbs-Sampling</a></li>
      </ul>
</li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Volker Schmid.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
